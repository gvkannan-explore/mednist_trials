{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Model Module for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as tt\n",
    "import matplotlib.pyplot as plt\n",
    "from monai import transforms as mT ## Breaks with numpy > 2.0\n",
    "from monai.utils import set_determinism\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import PosixPath, Path\n",
    "import json\n",
    "import numpy as np\n",
    "import yaml\n",
    "from typing import List, Dict, Tuple, Optional, Union, Any\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../envs/mednist.env\")\n",
    "root_dir = Path(os.environ.get(\"DATASET_DIR\"))\n",
    "data_dir = Path(os.environ.get(\"DATA_DIR\"))\n",
    "set_determinism(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir / 'hyperparam_mps_timm.yml', 'r') as outfile:\n",
    "    hparams_dict = yaml.safe_load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cpu',\n",
       " 'epochs': 4,\n",
       " 'finetune_frac': 0.1,\n",
       " 'ftune_batchsize': 16,\n",
       " 'in_channels': 1,\n",
       " 'loss': 'CrossEntropyLoss',\n",
       " 'lr': 1e-05,\n",
       " 'num_workers': 2,\n",
       " 'optimizer': 'AdamW',\n",
       " 'out_channels': 7,\n",
       " 'spatial_dims': 2,\n",
       " 'test_frac': 0.1,\n",
       " 'train_batchsize': 16,\n",
       " 'val_interval': 1,\n",
       " 'torch_device': 'mps',\n",
       " 'model_name': 'resnet34',\n",
       " 'pretrained': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(data_dir / \"random_split.json\"), \"r\") as fp:\n",
    "    data_split = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_header(path: str, pattern: str, replace_str: str) -> str:\n",
    "    return path.replace(pattern, replace_str,)\n",
    "\n",
    "## Preprocessing\n",
    "for split_type in [\"train\", \"ftune\", \"test\"]:\n",
    "    data_split[split_type]['image'] = [\n",
    "        replace_header(\n",
    "            path=img_path,\n",
    "            pattern=\"<DATASET_DIR>\",\n",
    "            replace_str=str(root_dir)\n",
    "            ) for img_path in data_split[split_type]['image']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define all relevant transforms!\n",
    "train_transforms = mT.Compose([\n",
    "    mT.LoadImage(image_only=True,),\n",
    "    mT.EnsureChannelFirst(), ## Add a channel to the batch dimension\n",
    "    mT.ScaleIntensity(),\n",
    "    mT.RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "    mT.RandFlip(spatial_axis=0, prob=0.5),\n",
    "    mT.RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "    mT.ToTensor(),\n",
    "    ])\n",
    "\n",
    "ftune_transforms = mT.Compose([\n",
    "    mT.LoadImage(image_only=True),\n",
    "    mT.EnsureChannelFirst(), ## Add a channel to the batch dimension\n",
    "    mT.ScaleIntensity(),\n",
    "])\n",
    "\n",
    "pred_transform = mT.Compose([\n",
    "    mT.Activations(softmax=True)])\n",
    "\n",
    "label_transform = mT.Compose([mT.AsDiscrete(to_onehot=hparams_dict['out_channels'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "monai.transforms.compose.Compose"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cpu',\n",
       " 'epochs': 4,\n",
       " 'finetune_frac': 0.1,\n",
       " 'ftune_batchsize': 16,\n",
       " 'in_channels': 1,\n",
       " 'loss': 'CrossEntropyLoss',\n",
       " 'lr': 1e-05,\n",
       " 'num_workers': 2,\n",
       " 'optimizer': 'AdamW',\n",
       " 'out_channels': 7,\n",
       " 'spatial_dims': 2,\n",
       " 'test_frac': 0.1,\n",
       " 'train_batchsize': 16,\n",
       " 'val_interval': 1,\n",
       " 'torch_device': 'mps',\n",
       " 'model_name': 'resnet34',\n",
       " 'pretrained': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image', 'label'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split['train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset!\n",
    "class MedNIST_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            data_dict: Dict, \n",
    "            transforms: mT.Compose, \n",
    "            image_key: str = \"image\",\n",
    "            label_key: str = \"label\",\n",
    "            ) -> None:\n",
    "        self.data = data_dict\n",
    "        self.transform = transforms\n",
    "        self.image_key = image_key\n",
    "        self.label_key = label_key\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[self.image_key])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            \"x\": self.transform(self.data[self.image_key][index]),\n",
    "            \"y\": int(self.data[self.label_key][index]),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "onebatch = {\n",
    "    \"image\": [data_split['train']['image'][0]],\n",
    "    \"label\": [data_split['train']['label'][0]],\n",
    "}\n",
    "\n",
    "train_ds = MedNIST_Dataset(\n",
    "    data_dict = onebatch,\n",
    "    transforms=train_transforms,)\n",
    "\n",
    "ftune_ds = MedNIST_Dataset(\n",
    "    data_dict = onebatch,\n",
    "    transforms=ftune_transforms,)\n",
    "\n",
    "## Dataloaders!\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=1,\n",
    "    num_workers=0)\n",
    "\n",
    "ftune_dl = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=1,\n",
    "    num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchmetrics import F1Score, Accuracy\n",
    "# rocauc = ROCAUCMetric()\n",
    "# ## Set average to None to get classwise.\n",
    "# acc = Accuracy(task=\"multiclass\", num_classes=hparams_dict['out_channels'])\n",
    "# f1 = F1Score(task=\"multiclass\", num_classes=hparams_dict['out_channels']) \n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outs = net(train_batch['x'].to(torch_device))\n",
    "#     pred = torch.stack([pred_transform(out.cpu()) for out in outs])\n",
    "#     gt = torch.stack([label_transform(i.cpu()) for i in train_batch['y']]) \n",
    "#     y_pred = pred ## Append or cat with multi-batch\n",
    "#     y_gt = gt\n",
    "\n",
    "# # acc = torch.eq(torch.stack(y_pred).argmax(dim=1), train_batch['y']).astype(int).mean() # Channel dimension is 1\n",
    "# out_acc = acc(y_pred.argmax(dim=1), y_gt.argmax(dim=1))\n",
    "# out_f1 = f1(y_pred, y_gt)\n",
    "\n",
    "# metric = rocauc(y_pred, y_gt)\n",
    "# metric = rocauc.aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rocauc': <monai.metrics.rocauc.ROCAUCMetric at 0x3543aa6c0>,\n",
       " 'acc': MulticlassAccuracy(),\n",
       " 'f1': MulticlassF1Score()}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics import Accuracy, F1Score, AUROC\n",
    "from monai.metrics import ROCAUCMetric\n",
    "\n",
    "metric_suite = {\n",
    "    \"rocauc\": ROCAUCMetric(),\n",
    "    \"acc\": Accuracy(task=\"multiclass\", num_classes=hparams_dict['out_channels']),\n",
    "    \"f1\": F1Score(task=\"multiclass\", num_classes=hparams_dict['out_channels'])}\n",
    "metric_suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams_dict['out_channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_tracker = []\n",
    "def train_epoch(\n",
    "        net: Any, \n",
    "        train_dl: torch.utils.data.DataLoader,\n",
    "        torch_device: str,\n",
    "        log_tracker: Dict,\n",
    "        optimizer: Any,\n",
    "        criterion: Any\n",
    "        ):\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    \n",
    "    for batch in  tqdm(train_dl):\n",
    "        imgs = batch['x'].to(torch_device)\n",
    "        labels = batch['y'].to(torch_device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        outputs = net(imgs)\n",
    "        batch_size = len(imgs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        step += batch_size\n",
    "    \n",
    "    epoch_loss /= step \n",
    "    log_tracker['train_loss'].append(epoch_loss)\n",
    "\n",
    "    return log_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(\n",
    "        net: Any, \n",
    "        val_dl: torch.utils.data.DataLoader,\n",
    "        torch_device: str,\n",
    "        criterion: Any,\n",
    "        log_tracker: Dict,\n",
    "        split_type: str = \"ftune\",\n",
    "        metric_suite: Dict = metric_suite,\n",
    "        ):\n",
    "\n",
    "    net.eval()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    y_pred, y_gt = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dl):\n",
    "            imgs = batch['x'].to(torch_device)\n",
    "            labels = batch['y'].to(torch_device)\n",
    "            outputs = net(imgs)\n",
    "            batch_size = len(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            step += batch_size\n",
    "\n",
    "            pred = [pred_transform(out.cpu()) for out in outputs]\n",
    "            gt = [label_transform(i.cpu()) for i in labels]\n",
    "            y_pred.append(pred) ## Append or cat with multi-batch\n",
    "            y_gt.append(gt)\n",
    "            metric_suite['rocauc'](pred, gt)\n",
    "\n",
    "    # acc = torch.eq(\n",
    "    #     torch.stack(y_pred).argmax(dim=1), # Channel dimension is 1\n",
    "    #     y_gt).astype(int).mean() \n",
    "    predY = torch.stack([pred for batch_pred in y_pred for pred in batch_pred])\n",
    "    gtY = torch.stack([pred for batch_pred in y_gt for pred in batch_pred])\n",
    "    # for pred, gt in zip(predY, gtY):\n",
    "    #     print(pred, gt)\n",
    "    metrics = metric_suite['rocauc'].aggregate(), metric_suite['acc'](predY.argmax(dim=1), gtY.argmax(dim=1)), metric_suite['f1'](predY.argmax(dim=1), gtY.argmax(dim=1))\n",
    "    # print(metrics)\n",
    "    epoch_loss /= step \n",
    "    log_tracker[f'{split_type}_loss'].append(epoch_loss)\n",
    "    log_tracker[f'{split_type}_acc'].append(metrics[1])\n",
    "    log_tracker[f'{split_type}_f1'].append(metrics[2])\n",
    "    log_tracker[f'{split_type}_rocauc'].append(metrics[0])\n",
    "    metric_suite['rocauc'].reset()\n",
    "    return log_tracker, predY, gtY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_tracker = {}\n",
    "split_type = \"ftune\"\n",
    "for key in [\"loss\", \"acc\", \"rocauc\", \"f1\"]:\n",
    "        log_tracker[f'{split_type}_{key}'] = []\n",
    "split_type = \"train\"\n",
    "for key in [\"loss\", \"acc\", \"rocauc\", \"f1\"]:\n",
    "        log_tracker[f'{split_type}_{key}'] = []\n",
    "\n",
    "# log_tracker = val_epoch(\n",
    "#         net=net, \n",
    "#         val_dl=ftune_dl,\n",
    "#         torch_device=torch_device,\n",
    "#         log_tracker=log_tracker,\n",
    "#         split_type=\"ftune\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks import nets as monai_nets\n",
    "\n",
    "torch_device = torch.device(hparams_dict['torch_device'])\n",
    "# net = timm.create_model(\n",
    "#     'resnet34', \n",
    "#     pretrained=hparams_dict['pretrained'], \n",
    "#     in_chans=hparams_dict['in_channels'],\n",
    "#     num_classes=hparams_dict['out_channels'],\n",
    "#     ).to(torch_device)\n",
    "net = monai_nets.DenseNet121(\n",
    "    spatial_dims=hparams_dict['spatial_dims'],\n",
    "    in_channels=hparams_dict['in_channels'],\n",
    "    out_channels=hparams_dict['out_channels']).to(torch_device)\n",
    "if hparams_dict['device'] == \"cuda\":\n",
    "    net = torch.compile(net)\n",
    "\n",
    "## Training related:\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58231fc4dcea4ac6a0e9b48300b70fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065a450490174006b75ecc9e1c4581ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Training:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m)):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m## train:\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     log_tracker \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_tracker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m## validate/finetune\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     log_tracker, predY, gtY \u001b[38;5;241m=\u001b[39m val_epoch(\n\u001b[1;32m     15\u001b[0m         net\u001b[38;5;241m=\u001b[39mnet, \n\u001b[1;32m     16\u001b[0m         val_dl\u001b[38;5;241m=\u001b[39mftune_dl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m     20\u001b[0m         split_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mftune\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n",
      "Cell \u001b[0;32mIn[48], line 19\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(net, train_dl, torch_device, log_tracker, optimizer, criterion)\u001b[0m\n\u001b[1;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(torch_device)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(imgs)\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/monai/networks/nets/densenet.py:254\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 254\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_layers(x)\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/monai/networks/nets/densenet.py:88\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     87\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/monai/data/meta_tensor.py:282\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 282\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[0;32m~/Documents/Projects/mednist_trials/.venv/lib/python3.12/site-packages/torch/_tensor.py:1437\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1437\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1439\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Training:\n",
    "\n",
    "for epoch in tqdm(range(3)):\n",
    "    ## train:\n",
    "    log_tracker = train_epoch(\n",
    "        net=net, \n",
    "        train_dl=train_dl,\n",
    "        torch_device=torch_device,\n",
    "        log_tracker=log_tracker,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        )\n",
    "    ## validate/finetune\n",
    "    log_tracker, predY, gtY = val_epoch(\n",
    "        net=net, \n",
    "        val_dl=ftune_dl,\n",
    "        torch_device=torch_device,\n",
    "        log_tracker=log_tracker,\n",
    "        criterion=criterion,\n",
    "        split_type=\"ftune\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ftune_loss': [1.8930829763412476,\n",
       "  1.8440446853637695,\n",
       "  1.7182203531265259,\n",
       "  1.5484941005706787,\n",
       "  1.3476866483688354,\n",
       "  1.1381984949111938,\n",
       "  0.9368500709533691,\n",
       "  0.7463205456733704,\n",
       "  0.5812855362892151,\n",
       "  0.4587387144565582,\n",
       "  0.35765063762664795,\n",
       "  0.2618445158004761,\n",
       "  0.21153660118579865,\n",
       "  0.14850567281246185,\n",
       "  0.12456497550010681,\n",
       "  0.09833212941884995,\n",
       "  0.07602529227733612,\n",
       "  0.06082341820001602,\n",
       "  0.05379243940114975,\n",
       "  0.04336537420749664,\n",
       "  0.04009545221924782,\n",
       "  0.02711883932352066,\n",
       "  0.025193143635988235,\n",
       "  0.024645835161209106,\n",
       "  0.026506297290325165,\n",
       "  0.02483121119439602,\n",
       "  0.02100251242518425,\n",
       "  0.021244702860713005,\n",
       "  0.015392908826470375,\n",
       "  0.014979499392211437],\n",
       " 'ftune_acc': [metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.)],\n",
       " 'ftune_rocauc': [nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan],\n",
       " 'ftune_f1': [metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.),\n",
       "  metatensor(1.)],\n",
       " 'train_loss': [2.152418613433838,\n",
       "  1.4021072387695312,\n",
       "  0.8114610910415649,\n",
       "  0.4159526228904724,\n",
       "  0.19765494763851166,\n",
       "  0.0909530445933342,\n",
       "  0.04617602005600929,\n",
       "  0.024987835437059402,\n",
       "  0.014554991386830807,\n",
       "  0.009175751358270645,\n",
       "  0.005435568280518055,\n",
       "  0.0034854395780712366,\n",
       "  0.002643188228830695,\n",
       "  0.001871859421953559,\n",
       "  0.0014037764631211758,\n",
       "  0.0010439666220918298,\n",
       "  0.0007898071780800819,\n",
       "  0.0006164796068333089,\n",
       "  0.0005193792167119682,\n",
       "  0.0004236992390360683,\n",
       "  0.00035553809721022844,\n",
       "  0.0003121604095213115,\n",
       "  0.00027009175391867757,\n",
       "  0.00025769727653823793,\n",
       "  0.0002115741081070155,\n",
       "  0.00019178935326635838,\n",
       "  0.00017224258044734597,\n",
       "  0.00016473366122227162,\n",
       "  0.00014149141497910023,\n",
       "  0.00014149141497910023],\n",
       " 'train_acc': [],\n",
       " 'train_rocauc': [],\n",
       " 'train_f1': []}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(metatensor(1), metatensor(1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predY.argmax(), gtY.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
